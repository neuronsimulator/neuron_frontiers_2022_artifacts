{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ccba94a-c55a-4dca-9b7d-ab9070975151",
   "metadata": {},
   "source": [
    "This is a notebook to parse Caliper results from running CoreNEURON on CPU/GPU into pretty figures for the 2021 NEURON frontiers research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57de96c7-1019-469c-8059-17dc96b75923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868481f5-6a57-40ee-ac51-e9fd07914cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcdefaults()\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rc('font', family='serif')\n",
    "#matplotlib.rcParams['text.latex.preamble'] = []\n",
    "fig_width = 6.97522 # \\textwidth in inches from Overleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fc8c3e-f79e-442e-9197-0652c7368c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['162118', '162123', '162128', '162133', '162138', '162143', '162148', '162153', '162158', '162163', '162168', '162173', '162178', '162183', '162188', '162193', '162198', '162203', '162208', '162213', '162218', '162223', '162228', '162233', '162238', '162243', '162248', '162253', '162258', '162263', '287843', '287844', '287845', '287846', '287847', '287848', '287849', '287850', '287851', '287852', '287853', '287854', '287855', '287856', '287857', '287858', '287859', '287860', '287861', '287862', '287863', '287864', '287865', '287866', '287867', '287868', '287869', '287870', '287871', '287872', '287873', '287874', '287875', '287876', '287877', '287878', '287879', '287880', '287881', '287882', '287883', '287884', '287885', '287886', '287887', '287888', '287889', '287890', '287891', '287892', '287893', '287894', '287895', '287896', '287897', '287898', '287899', '287900', '287901', '287902', '287903', '287904', '287905', '287906', '287907', '287908', '287909', '287910', '287911', '287912', '287913', '287914', '287915', '287916', '287917', '287918', '287919', '287920', '287921', '287922', '287923', '287924', '287925', '287926', '287927', '287928', '287929', '287930', '287931', '287932', '287933', '287934', '287935', '287936', '287937', '287938', '287939', '287940', '287941', '287942', '287943', '287944', '287945', '287946', '287947', '287948', '287949', '287950', '287951', '287952', '287953', '287954', '287955', '287956', '287957', '287958', '287959', '287960', '287961', '287962', '165791', '165792', '165793', '165794', '165795', '165796', '165797', '165798', '165799', '165800', '165801', '165802', '165803', '165804', '165805', '165806', '165807', '165808', '165809', '165810', '165811', '165812', '165813', '165814', '165815', '165816', '165817', '165818', '165819', '165820', '165821', '165822', '165823', '165824', '165825', '165826', '165827', '165828', '165829', '165830', '165831', '165832', '165833', '165834', '165835', '165836', '165837', '165838', '165839', '165840', '165841', '165842', '165843', '165844', '165845', '165846', '165847', '165848', '165849', '165850', '165851', '165852', '165853', '165854', '165855', '165856', '165857', '165858', '165859', '165860', '165861', '165862', '165863', '165864', '165865', '165866', '165867', '165868', '165869', '165870', '165871', '165872', '165873', '165874', '165875', '165876', '165877', '165878', '165879', '165880', '165881', '165882', '165883', '165884', '165885', '165886', '165887', '165888', '165889', '165890', '165891', '165892', '165893', '165894', '165895', '165896', '165897', '165898', '165899', '165900', '165901', '165902', '165903', '165904', '165905', '165906', '165907', '165908', '165909', '165910', '165911', '165912', '165913', '165914', '165915', '165916', '165917', '165918', '165919', '165920', '165921', '165922', '165923', '165924', '165925', '165926', '165927', '165928', '165929', '165930', '165931', '165932', '165933', '165934', '165935', '165936', '165937', '165938', '165939', '165940', '159791', '159796', '159801', '159806', '159811', '159816', '159821', '159826', '159831', '159836', '159841', '159846', '159851', '159856', '159861', '159866', '159871', '159876', '159881', '159886', '159891', '159896', '159901', '159906', '159911', '159916', '159921', '159926', '159931', '159936', '233347', '233348', '233349', '233350', '233351', '233352', '233353', '233354', '233355', '233356', '233357', '233358', '233359', '233360', '233361', '233362', '233363', '233364', '233365', '233366', '233367', '233368', '233369', '233370', '233371', '233372', '233373', '233374', '233375', '233376', '233377', '233378', '233379', '233380', '233381', '233382', '233383', '233384', '233385', '233386', '233387', '233388', '233389', '233390', '233391', '233392', '233393', '233394', '233395', '233396', '233397', '233398', '233399', '233400', '233401', '233402', '233403', '233404', '233405', '233406', '233407', '233408', '233409', '233410', '233411', '233412', '233413', '233414', '233415', '233416', '233417', '233418', '233419', '233420', '233421', '233422', '233423', '233424', '233425', '233426', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '33', '34', '35', '36', '37', '38', '39', '40', '41', '310122-153919', '310122-154326', '310122-154842', '310122-155140', '310122-155608', '310122-160019', '310122-160539', '310122-160835', '310122-161305', '310122-161712', '310122-162225', '310122-162520', '310122-162943', '310122-163352', '310122-163910', '310122-164206', '310122-164637', '310122-165044', '310122-165558', '310122-165855', '310122-170320', '310122-170730', '310122-171249', '310122-171545', '310122-172015', '310122-172422', '310122-172936', '310122-173231', '310122-173655', '310122-174105', '310122-174624', '310122-174919', '310122-175349', '310122-175756', '310122-180309', '310122-180606', '310122-181030', '310122-181440', '310122-181958', '310122-182253', '310122-182722', '310122-183129', '310122-183642', '310122-183937', '310122-184400', '310122-184810', '310122-185328', '310122-185623', '310122-190051', '310122-190458', '310122-191010', '310122-191305', '310122-191729', '310122-192139', '310122-192657', '310122-192952', '310122-193421', '310122-193828', '310122-194342', '310122-194638', '310122-195102', '310122-195511', '310122-200029', '310122-200324', '310122-200753', '310122-201200', '310122-201713', '310122-202007', '310122-202432', '310122-202842', '310122-203358', '310122-203653', '310122-204120', '310122-204526', '310122-205039', '310122-205332', '310122-205754', '310122-210204', '310122-210723', '310122-211018']\n"
     ]
    }
   ],
   "source": [
    "# Update these if you re-run the benchmarks. They are slurm job IDs.\n",
    "jobids = []\n",
    "# Results for the Olfactory Bulb model obtained after the BB5 upgrade and with\n",
    "# improvements to instrumentation, plus MPI_* function profiling and nwarp 2048\n",
    "jobids += [\"162118\",\"162123\",\"162128\",\"162133\",\"162138\",\"162143\",\"162148\",\"162153\",\"162158\",\"162163\",\"162168\",\"162173\",\"162178\",\"162183\",\"162188\",\"162193\",\"162198\",\"162203\",\"162208\",\"162213\",\"162218\",\"162223\",\"162228\",\"162233\",\"162238\",\"162243\",\"162248\",\"162253\",\"162258\",\"162263\",\"287843\",\"287844\",\"287845\",\"287846\",\"287847\",\"287848\",\"287849\",\"287850\",\"287851\",\"287852\",\"287853\",\"287854\",\"287855\",\"287856\",\"287857\",\"287858\",\"287859\",\"287860\",\"287861\",\"287862\",\"287863\",\"287864\",\"287865\",\"287866\",\"287867\",\"287868\",\"287869\",\"287870\",\"287871\",\"287872\",\"287873\",\"287874\",\"287875\",\"287876\",\"287877\",\"287878\",\"287879\",\"287880\",\"287881\",\"287882\",\"287883\",\"287884\",\"287885\",\"287886\",\"287887\",\"287888\",\"287889\",\"287890\",\"287891\",\"287892\",\"287893\",\"287894\",\"287895\",\"287896\",\"287897\",\"287898\",\"287899\",\"287900\",\"287901\",\"287902\",\"287903\",\"287904\",\"287905\",\"287906\",\"287907\",\"287908\",\"287909\",\"287910\",\"287911\",\"287912\",\"287913\",\"287914\",\"287915\",\"287916\",\"287917\",\"287918\",\"287919\",\"287920\",\"287921\",\"287922\",\"287923\",\"287924\",\"287925\",\"287926\",\"287927\",\"287928\",\"287929\",\"287930\",\"287931\",\"287932\",\"287933\",\"287934\",\"287935\",\"287936\",\"287937\",\"287938\",\"287939\",\"287940\",\"287941\",\"287942\",\"287943\",\"287944\",\"287945\",\"287946\",\"287947\",\"287948\",\"287949\",\"287950\",\"287951\",\"287952\",\"287953\",\"287954\",\"287955\",\"287956\",\"287957\",\"287958\",\"287959\",\"287960\",\"287961\",\"287962\"]\n",
    "# Results for the Hippocampus model obtained after the BB5 upgrade and with\n",
    "# improvements to instrumentation\",\" plus MPI_* function profiling and nwarp 2048\n",
    "jobids += [\"165791\",\"165792\",\"165793\",\"165794\",\"165795\",\"165796\",\"165797\",\"165798\",\"165799\",\"165800\",\"165801\",\"165802\",\"165803\",\"165804\",\"165805\",\"165806\",\"165807\",\"165808\",\"165809\",\"165810\",\"165811\",\"165812\",\"165813\",\"165814\",\"165815\",\"165816\",\"165817\",\"165818\",\"165819\",\"165820\",\"165821\",\"165822\",\"165823\",\"165824\",\"165825\",\"165826\",\"165827\",\"165828\",\"165829\",\"165830\",\"165831\",\"165832\",\"165833\",\"165834\",\"165835\",\"165836\",\"165837\",\"165838\",\"165839\",\"165840\",\"165841\",\"165842\",\"165843\",\"165844\",\"165845\",\"165846\",\"165847\",\"165848\",\"165849\",\"165850\",\"165851\",\"165852\",\"165853\",\"165854\",\"165855\",\"165856\",\"165857\",\"165858\",\"165859\",\"165860\",\"165861\",\"165862\",\"165863\",\"165864\",\"165865\",\"165866\",\"165867\",\"165868\",\"165869\",\"165870\",\"165871\",\"165872\",\"165873\",\"165874\",\"165875\",\"165876\",\"165877\",\"165878\",\"165879\",\"165880\",\"165881\",\"165882\",\"165883\",\"165884\",\"165885\",\"165886\",\"165887\",\"165888\",\"165889\",\"165890\",\"165891\",\"165892\",\"165893\",\"165894\",\"165895\",\"165896\",\"165897\",\"165898\",\"165899\",\"165900\",\"165901\",\"165902\",\"165903\",\"165904\",\"165905\",\"165906\",\"165907\",\"165908\",\"165909\",\"165910\",\"165911\",\"165912\",\"165913\",\"165914\",\"165915\",\"165916\",\"165917\",\"165918\",\"165919\",\"165920\",\"165921\",\"165922\",\"165923\",\"165924\",\"165925\",\"165926\",\"165927\",\"165928\",\"165929\",\"165930\",\"165931\",\"165932\",\"165933\",\"165934\",\"165935\",\"165936\",\"165937\",\"165938\",\"165939\",\"165940\"]\n",
    "# Results for NetPyNE M1 circuit obtained after the BB5 upgrade and with\n",
    "# improvements to instrumentation\",\" plus MPI_* function profiling and nwarp 2048\n",
    "# GPU runs are with 16 datasets\n",
    "jobids += [\"159791\",\"159796\",\"159801\",\"159806\",\"159811\",\"159816\",\"159821\",\"159826\",\"159831\",\"159836\",\"159841\",\"159846\",\"159851\",\"159856\",\"159861\",\"159866\",\"159871\",\"159876\",\"159881\",\"159886\",\"159891\",\"159896\",\"159901\",\"159906\",\"159911\",\"159916\",\"159921\",\"159926\",\"159931\",\"159936\",\"233347\",\"233348\",\"233349\",\"233350\",\"233351\",\"233352\",\"233353\",\"233354\",\"233355\",\"233356\",\"233357\",\"233358\",\"233359\",\"233360\",\"233361\",\"233362\",\"233363\",\"233364\",\"233365\",\"233366\",\"233367\",\"233368\",\"233369\",\"233370\",\"233371\",\"233372\",\"233373\",\"233374\",\"233375\",\"233376\",\"233377\",\"233378\",\"233379\",\"233380\",\"233381\",\"233382\",\"233383\",\"233384\",\"233385\",\"233386\",\"233387\",\"233388\",\"233389\",\"233390\",\"233391\",\"233392\",\"233393\",\"233394\",\"233395\",\"233396\",\"233397\",\"233398\",\"233399\",\"233400\",\"233401\",\"233402\",\"233403\",\"233404\",\"233405\",\"233406\",\"233407\",\"233408\",\"233409\",\"233410\",\"233411\",\"233412\",\"233413\",\"233414\",\"233415\",\"233416\",\"233417\",\"233418\",\"233419\",\"233420\",\"233421\",\"233422\",\"233423\",\"233424\",\"233425\",\"233426\"]\n",
    "# Results for the M1 model from GCP\n",
    "jobids += [\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"310122-153919\",\"310122-154326\",\"310122-154842\",\"310122-155140\",\"310122-155608\",\"310122-160019\",\"310122-160539\",\"310122-160835\",\"310122-161305\",\"310122-161712\",\"310122-162225\",\"310122-162520\",\"310122-162943\",\"310122-163352\",\"310122-163910\",\"310122-164206\",\"310122-164637\",\"310122-165044\",\"310122-165558\",\"310122-165855\",\"310122-170320\",\"310122-170730\",\"310122-171249\",\"310122-171545\",\"310122-172015\",\"310122-172422\",\"310122-172936\",\"310122-173231\",\"310122-173655\",\"310122-174105\",\"310122-174624\",\"310122-174919\",\"310122-175349\",\"310122-175756\",\"310122-180309\",\"310122-180606\",\"310122-181030\",\"310122-181440\",\"310122-181958\",\"310122-182253\",\"310122-182722\",\"310122-183129\",\"310122-183642\",\"310122-183937\",\"310122-184400\",\"310122-184810\",\"310122-185328\",\"310122-185623\",\"310122-190051\",\"310122-190458\",\"310122-191010\",\"310122-191305\",\"310122-191729\",\"310122-192139\",\"310122-192657\",\"310122-192952\",\"310122-193421\",\"310122-193828\",\"310122-194342\",\"310122-194638\",\"310122-195102\",\"310122-195511\",\"310122-200029\",\"310122-200324\",\"310122-200753\",\"310122-201200\",\"310122-201713\",\"310122-202007\",\"310122-202432\",\"310122-202842\",\"310122-203358\",\"310122-203653\",\"310122-204120\",\"310122-204526\",\"310122-205039\",\"310122-205332\",\"310122-205754\",\"310122-210204\",\"310122-210723\",\"310122-211018\"]\n",
    "print([\"\".join(x) for x in jobids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94407d-50dc-4bb2-9d4e-570807da9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason it's \"hard\" to get the path of the .ipynb file, so just hardcode it for now.\n",
    "repo_prefix = os.environ.get(\"PLOTTING_REPO_PREFIX\", \".\")\n",
    "# Load the Caliper result files into memory.\n",
    "all_data = {}\n",
    "number_of_runs = 10\n",
    "for jobid in jobids:\n",
    "    with open('{}/data/caliper-{}.json'.format(repo_prefix, jobid), 'r') as cfile:\n",
    "        job_data = json.load(cfile)\n",
    "    # Turn Caliper's list-of-dicts into a dict\n",
    "    data_entries = len(job_data['data'])\n",
    "    job_data['data'] = {x.pop('path', None): x for x in job_data['data']}\n",
    "    # Check we didn't accidentally drop anything due to a name collision\n",
    "    assert len(job_data['data']) == data_entries\n",
    "    # Figure out a \"short\" key for the results that includes whatever detail we're interested in.\n",
    "    # e.g. if we were to load the olfactory bulb results at the same time, we might want to put\n",
    "    #      `hip` and/or `obulb` into the key.    \n",
    "    backend = job_data['backend']\n",
    "    model = {\n",
    "        \"neurodamus-hippocampus/1.5.0.20211008-3.3.2\": 'hippocampus',\n",
    "        \"olfactory-bulb-3d/0.1.20211014\": 'olfactory-bulb-3d',\n",
    "        \"netpyne-m-one/0.1-20211206\": 'netpyne-m1',\n",
    "        \"netpyne-m-one/0.1-20211206-gcp\": 'netpyne-m1-gcp'\n",
    "    }[job_data['neurodamus_version']]\n",
    "    arch = backend[0:3]\n",
    "    assert arch in {'cpu', 'gpu'}\n",
    "    if arch == 'gpu':\n",
    "        if \"GCP\" in job_data:\n",
    "            num_gpus = int(job_data['gpus_per_node'])\n",
    "        else:\n",
    "            num_gpus = int(job_data['gpus_per_node'])*int(job_data['env']['SLURM_NNODES'])\n",
    "        #num_gpus = len(job_data['env']['SLURM_JOB_GPUS'].split(','))*int(job_data['env']['SLURM_NNODES'])  # Old way to calculate number of GPUs. Doesn't work after SLURM update\n",
    "        arch += '-{}gpus'.format(num_gpus)\n",
    "        if int(job_data['env'].get('NVCOMPILER_ACC_SYNCHRONOUS', '0')):\n",
    "            arch += '-accsync'\n",
    "            job_data['backend'] = job_data['backend'].replace('-synchronous', '')\n",
    "        job_data['backend'] = job_data['backend'].replace('-asynchronous', '')\n",
    "    translator = 'mod2c' if len(job_data['backend']) == 3 else job_data['backend'][4:]\n",
    "    if (model, arch, translator) in all_data:\n",
    "        # print(\"Processing {}\".format((model, arch, translator)))\n",
    "        # print(all_data[(model, arch, translator)]['data'].keys())\n",
    "        for key in all_data[(model, arch, translator)]['data'].keys():\n",
    "            # print(all_data[(model, arch, translator)]['data'][key].keys())\n",
    "            # print(\"printed\")\n",
    "            # print(\"key: {}\".format(key))\n",
    "            if key is not None:\n",
    "                # print(all_data[(model, arch, translator)]['data'][key].keys())\n",
    "                for timing_key in all_data[(model, arch, translator)]['data'][key].keys():\n",
    "                    # print(\"timing_key: {}\".format(timing_key))\n",
    "                    if type(all_data[(model, arch, translator)]['data'][key][timing_key]) is not list:\n",
    "                        all_data[(model, arch, translator)]['data'][key][timing_key] = [all_data[(model, arch, translator)]['data'][key][timing_key]]\n",
    "                    all_data[(model, arch, translator)]['data'][key][timing_key] += [job_data['data'][key][timing_key]]\n",
    "                    # print(all_data[(model, arch, translator)]['data'][key][timing_key])\n",
    "                    assert len(all_data[(model, arch, translator)]['data'][key][timing_key]) <= number_of_runs\n",
    "    else:\n",
    "        print(\"Added {}\".format((model, arch, translator)))\n",
    "        all_data[(model, arch, translator)] = job_data\n",
    "    # for key in job_data['data'].keys():\n",
    "    #     print(key)\n",
    "    #     print(job_data['data'][key])\n",
    "    #     for timing_key in job_data['data'][key].keys():\n",
    "    #         print(timing_key)\n",
    "    #         print(job_data['data'][key][timing_key])\n",
    "for job in all_data:\n",
    "    # print(all_data[job]['data'].keys())\n",
    "    print(job)\n",
    "    for key in all_data[job]['data'].keys():\n",
    "        # key_check = key == \"main/simulation\" or key == \"main/simulation/timestep/spike-exchange\" or key == \"main/simulation/timestep/deliver-events\"\n",
    "        # key_check = key == \"main/simulation\" or key == \"main/simulation/timestep/state-update\"\n",
    "        key_check = key == \"main/simulation/timestep/spike-exchange/spike-exchange/imbalance\" or key == \"main/simulation/timestep/spike-exchange\"\n",
    "        if key_check:\n",
    "            print(key)\n",
    "        for timing_key in all_data[job]['data'][key].keys():\n",
    "            timing_key_check = timing_key == \"inclusive_time_rank_avg\" or timing_key == \"inclusive_time_rank_max\"\n",
    "            if key_check and timing_key_check:\n",
    "            # if timing_key == \"inclusive_time_rank_avg\":\n",
    "                print(timing_key)\n",
    "                print(all_data[job]['data'][key][timing_key])\n",
    "            all_data[job]['data'][key][timing_key] = np.mean(all_data[job]['data'][key][timing_key])\n",
    "            if key_check and timing_key_check:\n",
    "            # if timing_key == \"inclusive_time_rank_avg\":\n",
    "                print(\"Mean: {}\".format(all_data[job]['data'][key][timing_key]))\n",
    "for job in all_data:\n",
    "    if job[0] == \"hippocampus\":\n",
    "        new_key_data = all_data[job][\"data\"].copy()\n",
    "        for key in all_data[job][\"data\"].keys():\n",
    "            hippocampus_spike_exchange_prefix = 'main/simulation/spike-exchange'\n",
    "            if key is not None and key.startswith(hippocampus_spike_exchange_prefix):\n",
    "                old_name = key\n",
    "                new_name = 'main/simulation/timestep/spike-exchange' + key[len(hippocampus_spike_exchange_prefix):]\n",
    "                spike_exchange_data = new_key_data.pop(old_name)\n",
    "                new_key_data[new_name] = spike_exchange_data\n",
    "                # Need to update the inclusive time of main/simulation/timestep, otherwise it will be smaller than the sum of its children.\n",
    "                if old_name == hippocampus_spike_exchange_prefix:\n",
    "                    new_key_data['main/simulation/timestep']['inclusive_time_rank_avg'] += spike_exchange_data['inclusive_time_rank_avg']\n",
    "        all_data[job][\"data\"] = new_key_data\n",
    "pprint(sorted(all_data.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39972d-b42c-4dcd-94cb-e77d04ea61f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_bars(axes, values, group_labels, group_sublabels, width=0.2, sep=0.05, xtick_rotation=0, labels=None):\n",
    "    r\"\"\"Make a bar chart containing several groups of bars.\n",
    "\n",
    "    This helps to create matplotlib bar charts that look like:\n",
    "   \n",
    "                       | = X\n",
    "       }               } = Y\n",
    "      |}               ] = Z\n",
    "      |}     [   |        \n",
    "      |}   |}[   |}[   |}  |\n",
    "      ----------------------\n",
    "      A     B     C     D  E\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    axes : Axes\n",
    "        Axes on which to draw the figure.\n",
    "    values : (N, M) ndarray\n",
    "        values[i][j] is the height of the i-th bar in the j-th group.\n",
    "        Non-finite values are ignored.\n",
    "    group_labels : array_like\n",
    "        String labels for the groups of bars. This would be [A, B, C, D, E] for\n",
    "        the example above. Length should match `M`.\n",
    "    group_sublabels : array_like\n",
    "        String labels for the members of each group, shown in the legend. This\n",
    "        would be [X, Y, Z] for the example above.\n",
    "        Length should match `N`.\n",
    "    width : float, optional\n",
    "        Width of each bar, in units where the centres of groups are separated\n",
    "        by one unit.\n",
    "    sep : float, optional\n",
    "        Gap between bars within the same group, in the same units as `width`.\n",
    "    xtick_rotation : float, optional\n",
    "        Amount by which to rotate the labels given in `group_labels`.\n",
    "    labels : str, optional\n",
    "        Annotate each bar with a label of its value (from `values`) formatted\n",
    "        using the format string `labels`.\n",
    "    \"\"\"\n",
    "    max_group_mult, num_groups = values.shape\n",
    "    assert len(group_labels) == num_groups\n",
    "    assert len(group_sublabels) == max_group_mult\n",
    "    # Handle all the i_bar-th bars from each group\n",
    "    for i_bar in range(max_group_mult):\n",
    "        xvs, yvs = [], []\n",
    "        for j_grp in range(num_groups):\n",
    "            # How many non-None values are there in this group?\n",
    "            grp_size = sum([1 for i in range(max_group_mult) if np.isfinite(values[i,j_grp])])\n",
    "            # Total width of all bars+separators in this group\n",
    "            grp_width = (grp_size-1)*sep + grp_size*width\n",
    "            xvs.append(j_grp - 0.5*grp_width + 0.5*width + i_bar*(width + sep))\n",
    "            yvs.append(values[i_bar,j_grp])\n",
    "        b = axes.bar(xvs, yvs, width=width, label=group_sublabels[i_bar])\n",
    "        if labels is not None:\n",
    "            axes.bar_label(b, fmt=labels, padding=2, fontsize=7)\n",
    "    axes.set_xticks(range(num_groups))\n",
    "    axes.set_xticklabels(group_labels, rotation=xtick_rotation, ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d9606-8751-4a68-b7b4-c3ecac37d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a chart showing the overall time. Left to right we want to show:\n",
    "overall_timing_keys = [\n",
    "    # Temporary workaround until we have Caliper results from NEURON too\n",
    "    # Hippocampus model, Average of SLURM jobs: 165261,165262,165263,165264,165265,165266,165267,165268,165269,165270\n",
    "    # Olfactory bulb model, Average of SLURM jobs: 2933462,162274,162275,162276,162277,162278,162279,162280,162281,162282\n",
    "    # Netpyne M1 model, Average of SLURM jobs: 165250,165251,165252,165253,165254,165255,165256,165257,165258,165259\n",
    "    ('NEURON\\n4$\\\\times$CPU', {'hippocampus': 1837.54839,\n",
    "                               'olfactory-bulb-3d': 1842.5,\n",
    "                               'netpyne-m1': 4925.654,\n",
    "                               'netpyne-m1-gcp': 4774.208}),\n",
    "    # <description to print on plot>, <arch>\n",
    "    # where the key in `all_data` will be (<model>, <arch>, <translator>)\n",
    "    ('CoreNEURON\\n4$\\\\times$CPU', 'cpu'),\n",
    "    ('CoreNEURON\\n4$\\\\times$GPU', 'gpu-4gpus'),\n",
    "    ('CoreNEURON\\n8$\\\\times$GPU', 'gpu-8gpus'),\n",
    "]\n",
    "overall_timing_translators = [\n",
    "    # <description to print on plot>, <translator for use in `all_data` key\n",
    "    ('MOD2C', 'mod2c'),\n",
    "    #('NMODL', 'nmodl'),\n",
    "    ('NMODL', 'nmodl-sympy'),\n",
    "]\n",
    "\n",
    "def make_overall_timing_plot(model, axes=None, speedup=False, y_lim=None, axes_title=None, **kwargs):\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots()\n",
    "    group_labels = [x[0] for x in overall_timing_keys]\n",
    "    group_sublabels = [x[0] for x in overall_timing_translators]\n",
    "    simulation_runtimes = np.full((len(overall_timing_translators), len(overall_timing_keys)), np.nan)\n",
    "    for n, (title, arch) in enumerate(overall_timing_keys):\n",
    "        if type(arch) == dict:\n",
    "            # Temporary hack for NEURON value that doesn't come from Caliper JSON\n",
    "            simulation_runtimes[0,n] = arch[model]\n",
    "        else:\n",
    "            for n_translator, (translator_title, translator) in enumerate(overall_timing_translators):\n",
    "                total_time = all_data[(model, arch, translator)]['data']['main/simulation']\n",
    "                simulation_runtimes[n_translator,n] = total_time['inclusive_time_rank_avg']\n",
    "    \n",
    "    if speedup:\n",
    "        # Convert to speedup w.r.t. NEURON\n",
    "        speedups_wrt_neuron = simulation_runtimes[0,0] / simulation_runtimes\n",
    "        # Don't show NEURON because it's 1 by definition\n",
    "        data_to_plot = speedups_wrt_neuron[:,1:]\n",
    "        print(\"data_to_plot\")\n",
    "        print(data_to_plot)\n",
    "        group_labels = [x.split('\\n')[1] for x in group_labels[1:]]\n",
    "        #if model == 'olfactory-bulb-3d':\n",
    "        #    bar_labels = '%.1fx'\n",
    "        #else:\n",
    "        bar_labels = '%.1fx'\n",
    "    else:\n",
    "        data_to_plot = simulation_runtimes\n",
    "        bar_labels = None\n",
    "        \n",
    "    grouped_bars(axes, data_to_plot, group_labels, group_sublabels,\n",
    "                 xtick_rotation=0 if speedup else 0, labels=bar_labels, **kwargs)\n",
    "\n",
    "    if speedup:\n",
    "        axes.set_ylabel(r'Speedup [$\\times$ NEURON]')\n",
    "        if y_lim is None:\n",
    "            factor = 25\n",
    "            # round up to the nearest `factor`\n",
    "            axes.set_ylim(0, np.ceil(data_to_plot.max()/factor)*factor)\n",
    "        else:\n",
    "            axes.set_ylim(0, y_lim)\n",
    "    else:\n",
    "        if y_lim is not None:\n",
    "            axes.set_ylim(0, y_lim)\n",
    "        axes.set_ylabel('Simulation time [s]')\n",
    "    axes.legend(title=axes_title, loc='upper left' if speedup else 'upper right')\n",
    "    \n",
    "make_overall_timing_plot('hippocampus')\n",
    "plt.savefig(os.path.join(repo_prefix, 'hippocampus-simulation-time.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159a461-509a-48c1-8858-d66a7196ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('olfactory-bulb-3d')\n",
    "plt.savefig(os.path.join(repo_prefix, 'olfactory-bulb-3d-simulation-time.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('netpyne-m1')\n",
    "plt.savefig(os.path.join(repo_prefix, 'netpyne-m1-simulation-time.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8924c-a634-4a7a-b684-c34a18122e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('hippocampus', speedup=True)\n",
    "plt.savefig(os.path.join(repo_prefix, 'hippocampus-simulation-speedup.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0312e7-d90a-4a7d-af8e-0259cdb18f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('olfactory-bulb-3d', speedup=True)\n",
    "plt.savefig(os.path.join(repo_prefix, 'olfactory-bulb-3d-simulation-speedup.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('netpyne-m1', speedup=True)\n",
    "plt.savefig(os.path.join(repo_prefix, 'netpyne-m1-simulation-speedup.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overall_timing_plot('netpyne-m1-gcp', speedup=True)\n",
    "plt.savefig(os.path.join(repo_prefix, 'netpyne-m1-gcp-simulation-speedup.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c20bdc-ef78-4720-88e1-21eb95800d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot showing how much NVCOMPILER_ACC_SYNCHRONOUS matters (or not)\n",
    "def make_async_speedup_plot(model):\n",
    "    sync_data = {}\n",
    "    for sync in [True, False]:\n",
    "        sync_str = '-accsync' if sync else ''\n",
    "        async_keys = [\n",
    "            ('4$\\\\times$GPU', 'gpu-4gpus' + sync_str),\n",
    "            ('8$\\\\times$GPU', 'gpu-8gpus' + sync_str),\n",
    "        ]\n",
    "        sync_group_labels = [x[0] for x in async_keys]\n",
    "        group_sublabels = [x[0] for x in overall_timing_translators]\n",
    "        simulation_runtimes = np.full((len(overall_timing_translators), len(async_keys)), np.nan)\n",
    "        for n, (title, arch) in enumerate(async_keys):\n",
    "            for n_translator, (translator_title, translator) in enumerate(overall_timing_translators):\n",
    "                total_time = all_data[(model, arch, translator)]['data']['main/simulation']\n",
    "                value = total_time['inclusive_time_rank_avg']\n",
    "                simulation_runtimes[n_translator,n] = value\n",
    "        sync_data[sync] = simulation_runtimes\n",
    "    async_speedup = 100*(sync_data[True] / sync_data[False] - 1)\n",
    "    fig, ax = plt.subplots()\n",
    "    grouped_bars(ax, async_speedup, sync_group_labels, group_sublabels, xtick_rotation=0)\n",
    "    plt.ylabel('Asynchronous execution speedup [%]')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(repo_prefix, model + '-simulation-async-gpu-speedup.pdf'), bbox_inches='tight')\n",
    "    \n",
    "make_async_speedup_plot('hippocampus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5343877-f478-459d-804f-511ffad37bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_async_speedup_plot('olfactory-bulb-3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eada7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_async_speedup_plot('netpyne-m1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd86ce-83f0-4250-9bce-569357311c12",
   "metadata": {},
   "source": [
    "Now make some plots of the different components of the simulation runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90120144-ab9f-4824-8731-33053df99243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def survey(axes, results, category_names, legend_axes=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    axes : Axes\n",
    "        Axes to plot on.\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    labels = [str(k) for k in results.keys()]#list(results.keys())\n",
    "    data = np.array(list(results.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    cmap = plt.get_cmap('tab10')#Paired')\n",
    "    axes.invert_yaxis()\n",
    "    axes.xaxis.set_visible(False)\n",
    "    axes.set_xlim(0, 1)\n",
    "\n",
    "    for i, colname in enumerate(category_names):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        rects = axes.barh(labels, widths, left=starts, height=0.5,\n",
    "                          label=colname, color=cmap.colors[i%len(cmap.colors)])\n",
    "    if legend_axes is None:\n",
    "        axes.legend(ncol=min(6, len(category_names)), bbox_to_anchor=(0, 0),\n",
    "                    loc='upper left', fontsize='small')\n",
    "    else:\n",
    "        h,l = axes.get_legend_handles_labels()\n",
    "        legend_axes.legend(h,l, borderaxespad=0, ncol=2, loc='upper left', fontsize='small', frameon=False)\n",
    "        legend_axes.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8057d22-641f-4aa6-aeba-cb1752c7b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a chart showing the overall time. Left to right we want to show:\n",
    "breakdown_keys = [\n",
    "    ('CoreNEURON\\n4 $\\\\times$ Cascade Lake', 'cpu'),\n",
    "#    ('CoreNEURON\\n4 $\\\\times$ V100 GPUs', 'gpu-4gpus-accsync'),\n",
    "    ('CoreNEURON\\n8 $\\\\times$ V100 GPUs', 'gpu-8gpus-accsync'),\n",
    "]\n",
    "\n",
    "breakdown_translators = [\n",
    "   ('MOD2C', 'mod2c'),\n",
    "#    ('NMODL', 'nmodl'),\n",
    "   ('NMODL', 'nmodl-sympy'),\n",
    "]\n",
    "\n",
    "known_sort_orders = {\n",
    "    ('main/simulation/timestep/deliver-events', 'main/simulation/timestep/matrix-solver', 'main/simulation/timestep/second-order-cur', 'main/simulation/timestep/setup-tree-matrix', 'main/simulation/timestep/state-update', 'main/simulation/timestep/update', 'main/simulation/timestep/spike-exchange', 'main/simulation/spike-exchange'):\n",
    "    ('main/simulation/timestep/deliver-events', 'main/simulation/timestep/setup-tree-matrix', 'main/simulation/timestep/matrix-solver', 'main/simulation/timestep/second-order-cur', 'main/simulation/timestep/update', 'main/simulation/timestep/state-update', 'main/simulation/timestep/spike-exchange', 'main/simulation/spike-exchange')\n",
    "}\n",
    "\n",
    "pretty_latex = {\n",
    "    'mod2c': 'MOD2C',\n",
    "    'nmodl-sympy': 'NMODL',\n",
    "    'cpu': '4$\\\\times$CPU',\n",
    "    'gpu-8gpus-accsync': '8$\\\\times$GPU',\n",
    "    ('cpu', 'mod2c'): '4$\\\\times$CPU, MOD2C',\n",
    "    ('cpu', 'nmodl'): '4$\\\\times$CPU, NMODL',\n",
    "    ('cpu', 'nmodl-sympy'): '4$\\\\times$CPU, NMODL',\n",
    "    ('gpu-4gpus-accsync', 'mod2c'): '4$\\\\times$GPU, MOD2C',\n",
    "    ('gpu-8gpus-accsync', 'mod2c'): '8$\\\\times$GPU, MOD2C',\n",
    "    ('gpu-4gpus-accsync', 'nmodl'): '4$\\\\times$GPU, NMODL',\n",
    "    ('gpu-8gpus-accsync', 'nmodl'): '8$\\\\times$GPU, NMODL',\n",
    "    ('gpu-4gpus-accsync', 'nmodl-sympy'): '4$\\\\times$GPU, NMODL',\n",
    "    ('gpu-8gpus-accsync', 'nmodl-sympy'): '8$\\\\times$GPU, NMODL',\n",
    "    'setup-tree-matrix': 'Current calculation',\n",
    "    'matrix-solver': 'Matrix solver',\n",
    "    'second-order-cur': '2nd order current',\n",
    "    'update': 'Voltage update',\n",
    "    'state-update': 'State update',\n",
    "    'leftovers': 'Other',\n",
    "    'deliver-events': 'Event delivery (inc. CPU to GPU transfers)',\n",
    "    'spike-exchange': 'Spike exchange',\n",
    "    'gap-v-transfer': 'Gap Junction voltage update'\n",
    "}\n",
    "\n",
    "# Extract the (immediate) children of a particular prefix\n",
    "def get_components_from_prefix(model, prefix, assume_zero=False, threshold=0, translators=None):\n",
    "    \"\"\"\n",
    "    prefix: string giving the part of the application that is to be analysed\n",
    "    assume_zero: if False, require all benchmark runs had the same children, if True, assume zero time for missing children\n",
    "    threshold: hide contributions that contribute less than this fraction in all benchmarks\n",
    "    \n",
    "    e.g. if we have\n",
    "    P\n",
    "    P/A\n",
    "    P/B\n",
    "    P/B/1\n",
    "    P/B/2\n",
    "    P/C\n",
    "    Q\n",
    "    R\n",
    "    \n",
    "    then prefix=P will extract P/A, P/B and P/C\n",
    "    \"\"\"\n",
    "    # Make sure the trailing / is there\n",
    "    if prefix[-1] != '/': prefix += '/'\n",
    "    # Get the union of all the children of `prefix` seen across the different benchmark runs.\n",
    "    # Preserve order, consider it an error if the order is inconsistent across benchmark runs.\n",
    "    entries = []\n",
    "    for title, arch in breakdown_keys:\n",
    "        for translator_title, translator in breakdown_translators:\n",
    "            key_data = all_data[(model, arch, translator)]['data']\n",
    "            local_entries = tuple(sorted([x for x in key_data.keys()\n",
    "                                          if x is not None\n",
    "                                          and x.startswith(prefix)\n",
    "                                          and x.count('/', len(prefix)) == 0]))\n",
    "            local_entries = known_sort_orders.get(local_entries, local_entries)\n",
    "            if len(entries) == 0:\n",
    "                entries = local_entries\n",
    "            elif entries != local_entries:\n",
    "                s1, s2 = set(entries), set(local_entries)\n",
    "                if s1 == s2:\n",
    "                    print(\"Ignoring differing order of entries\")\n",
    "                elif len(s1 - s2):\n",
    "                    print(\"Ignoring {} missing in {} (ordering not checked!)\".format(s1 - s2, (arch, translator)))\n",
    "                else:\n",
    "                    # Not implemented\n",
    "                    assert False\n",
    "    output_data = {}\n",
    "    for n, (title, arch) in enumerate(breakdown_keys):\n",
    "        for n_translator, (translator_title, translator) in enumerate(breakdown_translators):\n",
    "            if translators is not None and not translator in translators: continue\n",
    "            key = (model, arch, translator)\n",
    "            key_data = all_data[key]['data']\n",
    "            def get(entry):\n",
    "                if entry in key_data:\n",
    "                    return key_data[entry]['inclusive_time_rank_avg']\n",
    "                elif assume_zero:\n",
    "                    return 0.0\n",
    "                raise Exception(\"{} has no value for {}\".format(key, entry))                    \n",
    "            # Normalise values to the time recorded for the prefix\n",
    "            values = [get(k)/get(prefix[:-1]) for k in entries]\n",
    "            output_data[(arch, translator)] = values\n",
    "    # See if the threshold removes anything\n",
    "    to_cull = []\n",
    "    for i in range(len(entries)):\n",
    "        if all(v[i] < threshold for v in output_data.values()):\n",
    "            to_cull.append(i)\n",
    "    to_cull.reverse()\n",
    "    entries = list(entries)\n",
    "    for i in to_cull:\n",
    "        # remove the i-th values and the i-th title from `entries`\n",
    "        print(\"Suppressing\", entries.pop(i))\n",
    "        for v in output_data.values():\n",
    "            v.pop(i)\n",
    "    # Remove the explicitly specified prefix\n",
    "    value_names = [k[len(prefix):] for k in entries]\n",
    "    # See if we can find another common `foobar-` prefix to remove\n",
    "    ind = value_names[0].find('-')\n",
    "    if ind != -1:\n",
    "        extra_prefix = value_names[0][:ind+1]\n",
    "        if all([k.startswith(extra_prefix) for k in value_names]):\n",
    "            value_names = [k[len(extra_prefix):] for k in value_names]\n",
    "            prefix += extra_prefix       \n",
    "    # Add an explicit entry for \"leftovers\" instead of leaving a white void\n",
    "    value_names.append('leftovers')\n",
    "    for v in output_data.values():\n",
    "        v.append(1.0 - sum(v))\n",
    "        print('leftover', v[-1])\n",
    "    return value_names, output_data, prefix\n",
    "\n",
    "def make_plot(model, prefix, axes=None, latexify=True, legend_axes=None, **kwargs):\n",
    "    save_figure = False\n",
    "    if axes is None:\n",
    "        fix, axes = plt.subplots()\n",
    "        save_figure = True\n",
    "    plot_kwargs = {x: kwargs.pop(x) for x in ['title'] if x in kwargs}\n",
    "    value_names, values, prefix = get_components_from_prefix(model, prefix, **kwargs)\n",
    "\n",
    "    # Relies on modern Python's order-preserving dicts\n",
    "    values = {k: values[k] for k in sorted(values.keys(), reverse=True)}\n",
    "        \n",
    "    # Helper to allow substitution of pretty LaTeX\n",
    "    def latex(x):\n",
    "        return pretty_latex.get(x, str(x)) if latexify else str(x)\n",
    "    \n",
    "    # Beautify the different categories (i.e. the names in the legend)\n",
    "    value_names = [latex(x) for x in value_names]\n",
    "    \n",
    "    # Try and de-duplicate the configuration names a bit.\n",
    "    # If the keys are [(A, X...), (A, Y...), (B, Z...)] then remove the first\n",
    "    # elements and put a second y-axis on the RHS with only [A, B] and remove\n",
    "    # the first elements from the LHS.\n",
    "    if all([type(x) == tuple for x in values.keys()]):\n",
    "        right_labels = [latex(x[0]) for x in values.keys()]\n",
    "        left_labels  = [latex(x[1:] if len(x) > 2 else x[1]) for x in values.keys()]\n",
    "    else:\n",
    "        left_labels = [latex(x) for x in values.keys()]\n",
    "        right_labels = None\n",
    "    \n",
    "    cmap = plt.get_cmap('tab10') # 'Paired' also works OK\n",
    "    \n",
    "    data = np.array(list(values.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    \n",
    "    y_pos = np.arange(len(left_labels))\n",
    "    for i, colname in enumerate(value_names):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        rects = axes.barh(y_pos, widths, left=starts, height=0.5,\n",
    "                          label=colname, color=cmap.colors[i%len(cmap.colors)])\n",
    "    if len(set(left_labels)) > 1:\n",
    "        axes.set_yticks(y_pos)\n",
    "        axes.set_yticklabels(left_labels)\n",
    "    else:\n",
    "        axes.set_yticks([])\n",
    "    axes.xaxis.set_visible(False)\n",
    "    axes.set_xlim(0, 1)\n",
    "\n",
    "    # De-duplicate the RHS labels and compute average y positions for the\n",
    "    # duplicate elements.\n",
    "    rhs_axes = axes.twinx()\n",
    "    rhs_axes.set_ylim(axes.get_ylim())\n",
    "    last_count, rhs_positions, rhs_labels = 0, [], []\n",
    "    for i, label in enumerate(right_labels):\n",
    "        if len(rhs_labels) and label == rhs_labels[-1]:\n",
    "            last_count += 1\n",
    "            rhs_positions[-1] += i\n",
    "        else:\n",
    "            if len(rhs_labels):\n",
    "                rhs_positions[-1] /= last_count\n",
    "            last_count = 1\n",
    "            rhs_positions.append(i)\n",
    "            rhs_labels.append(label)\n",
    "    rhs_positions[-1] /= last_count\n",
    "    rhs_axes.set_yticks(rhs_positions)\n",
    "    rhs_axes.set_yticklabels(rhs_labels)\n",
    "    rhs_axes.yaxis.set_tick_params(length=0) \n",
    "\n",
    "    if legend_axes is None:\n",
    "        axes.legend(ncol=min(6, len(value_names)), bbox_to_anchor=(0, 0),\n",
    "                    loc='upper left', fontsize='small')\n",
    "    else:\n",
    "        h,l = axes.get_legend_handles_labels()\n",
    "        legend_axes.legend(h,l, borderaxespad=0, ncol=2, loc='upper left', fontsize='small', frameon=False)\n",
    "        legend_axes.axis(\"off\")        \n",
    "        \n",
    "    if save_figure:\n",
    "        filename = model + '-' + prefix[5:].replace('/', '-')\n",
    "        if filename[-1] == '-': filename = filename[:-1]\n",
    "        filename += '.pdf'\n",
    "        plt.savefig(os.path.join(repo_prefix, filename), bbox_inches='tight')\n",
    "\n",
    "make_plot('hippocampus', 'main/simulation/timestep', threshold=5e-2, translators={'nmodl-sympy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138660bb-390c-4997-aa93-aac00b828261",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot('olfactory-bulb-3d', 'main/simulation/timestep', threshold=3e-2, translators={'nmodl-sympy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110be3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot('netpyne-m1', 'main/simulation/timestep', threshold=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf7d6e-11fc-4d12-bd2f-81e59989929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('text', usetex=False)\n",
    "make_plot('hippocampus', 'main/simulation/timestep/state-update', assume_zero=True, threshold=1e-2)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45de7a9-6c44-4a40-b63e-e0e040b51c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('text', usetex=False)\n",
    "make_plot('olfactory-bulb-3d', 'main/simulation/timestep/state-update', assume_zero=True, threshold=1e-2)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('text', usetex=False)\n",
    "make_plot('netpyne-m1', 'main/simulation/timestep/state-update', assume_zero=True, threshold=1e-2)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd21cf-8189-451c-a202-f966af9d7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('text', usetex=False)\n",
    "make_plot('hippocampus', 'main/simulation/timestep/setup-tree-matrix', threshold=2e-2)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35b95b-1f76-472e-b013-43fde9fd63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('text', usetex=False)\n",
    "make_plot('olfactory-bulb-3d', 'main/simulation/timestep/setup-tree-matrix', threshold=2e-2)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eae495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because of the following:\n",
    "# Ignoring {'main/simulation/timestep/setup-tree-matrix/cur-cadyn', 'main/simulation/timestep/setup-tree-matrix/cur-catcb', 'main/simulation/timestep/setup-tree-matrix/cur-iconc_Ca', 'main/simulation/timestep/setup-tree-matrix/cur-cadad'} missing in ('cpu', 'nmodl-sympy') (ordering not checked!)\n",
    "# Ignoring {'main/simulation/timestep/setup-tree-matrix/cur-cadyn', 'main/simulation/timestep/setup-tree-matrix/cur-catcb', 'main/simulation/timestep/setup-tree-matrix/cur-iconc_Ca', 'main/simulation/timestep/setup-tree-matrix/cur-cadad'} missing in ('gpu-8gpus-accsync', 'nmodl-sympy') (ordering not checked!)\n",
    "# matplotlib.rc('text', usetex=False)\n",
    "# make_plot('netpyne-m1', 'main/simulation/timestep/setup-tree-matrix', threshold=2e-2)\n",
    "# matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a8bf2-c409-4487-a1ed-0c379612ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_summary_plot(model, rhs_kwargs={}):\n",
    "    model_figsize = (fig_width, fig_width/2)\n",
    "    fig, axs = plt.subplots(2, 2, dpi=300,\n",
    "                                  figsize=model_figsize,\n",
    "                                  tight_layout=True,\n",
    "                                  gridspec_kw={\n",
    "                                      # Minimize space above legend.\n",
    "                                      'hspace': 0,\n",
    "                                      'width_ratios': [1, 2],\n",
    "                                      'height_ratios': [3, 1],\n",
    "                                  })\n",
    "    # Merge the upper/lower axes in the first column\n",
    "    gs = axs[0, 0].get_gridspec()\n",
    "    for ax in axs[:,0]: ax.remove()\n",
    "    ax1 = fig.add_subplot(gs[:,0])\n",
    "    # Upper right\n",
    "    ax2 = axs[0,1]\n",
    "    # Lower right\n",
    "    ax3 = axs[1,1]\n",
    "    # Draw the speedup bar chart on the left subplot\n",
    "    make_overall_timing_plot(model, axes=ax1, speedup=True, width=0.4, sep=0.07)\n",
    "    ax1.set_title(\"A\", loc=\"left\", fontdict={'weight': 'bold'})\n",
    "    make_plot(model, 'main/simulation/timestep', axes=ax2, latexify=True, legend_axes=ax3, threshold=5e-2, **rhs_kwargs)\n",
    "    ax2.set_title(\"B\", loc=\"left\", fontdict={'weight': 'bold'})\n",
    "    fig.savefig(model + '-speed-up-and-break-down.pdf', bbox_inches='tight')\n",
    "\n",
    "make_summary_plot('hippocampus', rhs_kwargs={'translators': {'nmodl-sympy'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14204a4a-61e5-4c92-bd50-242efa080519",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summary_plot('olfactory-bulb-3d', rhs_kwargs={'translators': {'nmodl-sympy'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c917962",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summary_plot('netpyne-m1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2263de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summary_plot('netpyne-m1-gcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_netpyne_summary_plot():\n",
    "    fig, axs = plt.subplots(2, 2, dpi=300,\n",
    "                                  figsize=(fig_width, fig_width/2),\n",
    "                                  tight_layout=True,\n",
    "                                  gridspec_kw={\n",
    "                                      # Minimize space above legend.\n",
    "                                      'hspace': 0,\n",
    "                                      'width_ratios': [1, 1],\n",
    "                                      'height_ratios': [3, 3],\n",
    "                                  })\n",
    "    # Merge the upper/lower axes in the first column\n",
    "    gs = axs[0, 0].get_gridspec()\n",
    "    for ax in axs[:,0]: ax.remove()\n",
    "    ax1 = fig.add_subplot(gs[:,0])\n",
    "    # Upper right\n",
    "    gs = axs[0, 1].get_gridspec()\n",
    "    for ax in axs[:,1]: ax.remove()\n",
    "    ax2 = fig.add_subplot(gs[:,1])\n",
    "    # Lower right\n",
    "    ax3 = axs[1,1]\n",
    "    # Draw the speedup bar chart on the left subplot\n",
    "    y_lim=45\n",
    "    make_overall_timing_plot(\"netpyne-m1\", axes=ax1, speedup=True, y_lim=y_lim, axes_title=\"BB5\", width=0.4, sep=0.05)\n",
    "    ax1.set_title(\"A\", loc=\"left\", fontdict={'weight': 'bold'})\n",
    "    make_overall_timing_plot(\"netpyne-m1-gcp\", axes=ax2, speedup=True, y_lim=y_lim, axes_title=\"Google Cloud\", width=0.4, sep=0.05)\n",
    "    ax2.set_title(\"B\", loc=\"left\", fontdict={'weight': 'bold'})\n",
    "    fig.savefig('netpyne-summary.pdf', bbox_inches='tight')\n",
    "\n",
    "make_netpyne_summary_plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
